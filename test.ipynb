{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e61ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import os\n",
    "import librosa  # for sound processing.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a96985f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mel_spec(audio, transpose=True, expand_dims=(0,)):\n",
    "    \"\"\"\n",
    "    Calculate a mal spectrogram from raw audio waveform\n",
    "    Note: The parameters of the spectrograms are in the config.py file.\n",
    "    Args:\n",
    "        audio : numpy.array, raw waveform to compute the spectrogram\n",
    "\n",
    "    Returns:\n",
    "        numpy.array\n",
    "        containing the mel spectrogram\n",
    "    \"\"\"\n",
    "    # Compute spectrogram\n",
    "    ham_win = np.hamming(n_window)\n",
    "    # audio, _ = librosa.load(filename, sr=sample_rate)\n",
    "    #     print(type(audio))\n",
    "\n",
    "    audio = np.array(audio)\n",
    "    spec = librosa.stft(\n",
    "        audio,\n",
    "        n_fft=n_window,\n",
    "        hop_length=hop_length,\n",
    "        window=ham_win,\n",
    "        center=True,\n",
    "        pad_mode='reflect'\n",
    "    )\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        S=np.abs(spec),  # amplitude, for energy: spec**2 but don't forget to change amplitude_to_db.\n",
    "        sr=sr,\n",
    "        n_mels=n_mels,\n",
    "        fmin=f_min, fmax=f_max,\n",
    "        htk=False, norm=None)\n",
    "\n",
    "    if save_log_feature:\n",
    "        mel_spec = librosa.amplitude_to_db(mel_spec)  # 10 * log10(S**2 / ref), ref default is 1\n",
    "\n",
    "    if transpose:\n",
    "        mel_spec = mel_spec.T\n",
    "\n",
    "    if len(expand_dims) > 0:\n",
    "        mel_spec = np.expand_dims(mel_spec, axis=expand_dims)\n",
    "\n",
    "    return mel_spec\n",
    "\n",
    "\n",
    "def pad_zeros(array, size, axis):\n",
    "    shape = list(array.shape)\n",
    "\n",
    "    if shape[axis] > size:\n",
    "        shape[axis] = size\n",
    "        shape = tuple(slice(0, i) for i in shape)\n",
    "        return array[shape]\n",
    "\n",
    "    shape[axis] = size - shape[axis]\n",
    "    return np.concatenate((array, np.zeros(shape)), axis=axis)\n",
    "\n",
    "\n",
    "def train(cfg):\n",
    "    csv_path = data_path + \"/metadata/UrbanSound8K.csv\"\n",
    "    data = pd.read_csv(csv_path)\n",
    "    train_idx, test_idx = train_test_split(data.index, test_size=0.3, stratify=data['class'])\n",
    "    valid_idx, test_idx = train_test_split(test_idx, test_size=0.33, stratify=data.loc[test_idx]['class'])\n",
    "\n",
    "    # Split data on train / valid / test\n",
    "    data.at[train_idx, 'split'] = 'train'\n",
    "    data.at[valid_idx, 'split'] = 'valid'\n",
    "    data.at[test_idx, 'split'] = 'test'\n",
    "\n",
    "    if '.' in csv_path:\n",
    "        data.to_csv(csv_path[:-4] + '_split' + '.csv')\n",
    "    else:\n",
    "        data.to_csv(csv_path + '_split' + '.csv')\n",
    "\n",
    "    # Read audio files and generate features\n",
    "    if 'fold' in data.columns and \\\n",
    "            sum([a.startswith(\"fold\") for a in next(os.walk(data_path))[1]]) > 2:\n",
    "        data['audio'] = data[['slice_file_name', 'fold']].apply(lambda x: librosa.load(data_path + \"/fold{}/\".format(x.fold) + x.slice_file_name, sr=sr), axis=1)\n",
    "\n",
    "    else:\n",
    "        data['audio'] = data['slice_file_name'].apply(lambda x: librosa.load(data_path + '/' + x, sr=sr))\n",
    "\n",
    "    data['features'] = data['audio'].apply(calculate_mel_spec)\n",
    "\n",
    "    # Pad features to the same shape\n",
    "    if pad_zero is None:\n",
    "        pad_size = data['features'].apply(lambda x: x.shape[1]).max()\n",
    "    else:\n",
    "        pad_size = pad_size\n",
    "\n",
    "    data['features'] = data['features'].apply(lambda x: pad_zeros(x, pad_size, axis=1))\n",
    "    print(\"Here\")\n",
    "    X_train, X_valid, X_test = (np.array(data[data.split == sp]['features'].tolist())\n",
    "                                for sp in ['train', 'valid', 'test'])\n",
    "\n",
    "    lb = LabelEncoder().fit(classes)\n",
    "    y_train, y_valid, y_test = (\n",
    "        np_utils.to_categorical(lb.transform(np.array(data[data.split == sp]['class'].tolist())))\n",
    "        for sp in ['train', 'valid', 'test'])\n",
    "\n",
    "    # Train model\n",
    "    model = CNN()\n",
    "    model.compile(optimizers.RMSprop(lr=0.0005, decay=1e-6), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    model.fit(X_train, y_train, batch_size=64, epochs=150, validation_data=(X_valid, y_valid))\n",
    "\n",
    "    if save_path:\n",
    "        model.save(save_path)\n",
    "\n",
    "    # Test model quality\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=lb.classes_))\n",
    "\n",
    "\n",
    "def eval(cfg):\n",
    "    if os.path.exists(cfg.data_path[:-4] + '_split_' + '.csv'):\n",
    "        data = pd.read_csv(cfg.data_path[:-4] + '_split_' + '.csv')\n",
    "        data = data[data.split == 'test']\n",
    "    elif os.path.exists(cfg.data_path + '_split_' + '.csv'):\n",
    "        data = pd.read_csv(cfg.data_path + '_split_' + '.csv')\n",
    "        data = data[data.split == 'test']\n",
    "    else:\n",
    "        data = pd.read_csv(cfg.data_path)\n",
    "\n",
    "    # Read audio files and generate features\n",
    "    if 'fold' in data.columns() and \\\n",
    "            sum([a.startswith(\"fold\") for a in next(os.walk(\"UrbanSound8K\"))[1]]) > 2:\n",
    "        data['audio'] = data[['slice_file_name', 'fold']].apply(\n",
    "            lambda x: librosa.load(\"UrbanSound8K/\" + \"fold{}/\".format(x.fold) + x.slice_file_name, sr=cfg.sr))\n",
    "\n",
    "    else:\n",
    "        data['audio'] = data['slice_file_name'].apply(lambda x: librosa.load(x, sr=cfg.sr))\n",
    "\n",
    "    data['features'] = data['audio'].apply(calculate_mel_spec)\n",
    "    X = np.array(data['features'].apply(lambda x: pad_zeros(x, pad_size, axis=1)).tolist())\n",
    "\n",
    "    lb = LabelEncoder().fit(cfg.classes)\n",
    "    y = np_utils.to_categorical(lb.transform(np.array(data['class'].tolist())))\n",
    "\n",
    "    model = keras.load(cfg.model_path)\n",
    "    print(classification_report(y, model.predict(X), target_names=lb.classes_))\n",
    "\n",
    "\n",
    "def predict(cfg, return_audio=False):\n",
    "    audio, _ = librosa.load(cfg.filename, sr=cfg.sr)\n",
    "    features = calculate_mel_spec(audio)\n",
    "    features = pad_zeros(features, cfg.pad_size, cfg.pad_axis)\n",
    "    model = keras.load(cfg.model_path)\n",
    "    pred_label = lb.inverse_transform([np.argmax(model(features))])\n",
    "    if return_audio:\n",
    "        return pred_label, audio\n",
    "    else:\n",
    "        return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54791f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "data_path = \"UrbanSound8K\"\n",
    "sr = 44100\n",
    "model_path = ''\n",
    "\n",
    "n_window = 2048\n",
    "hop_length = 511\n",
    "n_mels = 64\n",
    "max_len_seconds = 10.\n",
    "max_frames = math.ceil(max_len_seconds * sr / hop_length)\n",
    "pooling_time_ratio = 8\n",
    "\n",
    "f_min = 0.\n",
    "f_max = 22050.\n",
    "save_log_feature = False\n",
    "\n",
    "classes = ['air_conditioner', 'car_horn', 'children_playing', 'dog_bark', 'drilling',\n",
    "           'engine_idling', 'gun_shot', 'jackhammer', 'siren', 'street_music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d43bb0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f93e676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available objects for config:\n",
      "     AliasManager\n",
      "     DisplayFormatter\n",
      "     HistoryManager\n",
      "     IPCompleter\n",
      "     IPKernelApp\n",
      "     LoggingMagics\n",
      "     MagicsManager\n",
      "     OSMagics\n",
      "     PrefilterManager\n",
      "     ScriptMagics\n",
      "     StoreMagics\n",
      "     ZMQInteractiveShell\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d1c9a9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a66b01ebd0d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-2d85b6ea1f1d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'fold'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fold\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'audio'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'slice_file_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/fold{}/\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7767\u001b[0m         )\n\u001b[1;32m-> 7768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-2d85b6ea1f1d>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'fold'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fold\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'audio'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'slice_file_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/fold{}/\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoxr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f19c7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = data_path + \"/metadata/UrbanSound8K.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "train_idx, test_idx = train_test_split(data.index, test_size=0.3, stratify=data['class'])\n",
    "valid_idx, test_idx = train_test_split(test_idx, test_size=0.33, stratify=data.loc[test_idx]['class'])\n",
    "\n",
    "# Split data on train / valid / test\n",
    "data.at[train_idx, 'split'] = 'train'\n",
    "data.at[valid_idx, 'split'] = 'valid'\n",
    "data.at[test_idx, 'split'] = 'test'\n",
    "\n",
    "if '.' in csv_path:\n",
    "    data.to_csv(csv_path[:-4] + '_split' + '.csv')\n",
    "else:\n",
    "    data.to_csv(csv_path + '_split' + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b5ccde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7881e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # Read audio files and generate features\n",
    "if 'fold' in data.columns and \\\n",
    "        sum([a.startswith(\"fold\") for a in next(os.walk(data_path))[1]]) > 2:\n",
    "    data['audio'] = data[['slice_file_name', 'fold']].apply(lambda x: librosa.load(data_path + \"/fold{}/\".format(x.fold) + x.slice_file_name, sr=sr)[0], axis=1)\n",
    "\n",
    "else:\n",
    "    data['audio'] = data['slice_file_name'].apply(lambda x: librosa.load(data_path + '/' + x, sr=sr)[0])\n",
    "\n",
    "data['features'] = data['audio'].apply(calculate_mel_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3fc683f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (1, 346, 64)\n",
       "1     (1, 346, 64)\n",
       "2     (1, 346, 64)\n",
       "3     (1, 346, 64)\n",
       "4     (1, 346, 64)\n",
       "          ...     \n",
       "95    (1, 346, 64)\n",
       "96    (1, 346, 64)\n",
       "97    (1, 346, 64)\n",
       "98    (1, 346, 64)\n",
       "99    (1, 346, 64)\n",
       "Name: features, Length: 100, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['features'].apply(lambda x:x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f57be3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7da3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad features to the same shape\n",
    "if pad_size is None:\n",
    "    pad_size = data['features'].apply(lambda x: x.shape[1]).max()\n",
    "else:\n",
    "    pad_size = pad_size\n",
    "\n",
    "data['features'] = data['features'].apply(lambda x: pad_zeros(x, pad_size, axis=1))\n",
    "\n",
    "X_train, X_valid, X_test = (np.array(data[data.split == sp]['features'].tolist())\n",
    "                            for sp in ['train', 'valid', 'test'])\n",
    "\n",
    "lb = LabelEncoder().fit(classes)\n",
    "y_train, y_valid, y_test = (\n",
    "    np_utils.to_categorical(lb.transform(data[data.split == sp]['class'].tolist()), num_classes=len(lb.classes_))\n",
    "    for sp in ['train', 'valid', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f055f6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32),\n",
       " array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92195902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 346, 64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dd1fbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 1, 346, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 86, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 86, 32)         18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 43, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 43, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 43, 16)         4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 21, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 21, 4)          580       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 10, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 10, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               5248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 67,134\n",
      "Trainable params: 67,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 5.3136 - accuracy: 0.0548 - val_loss: 1.9254 - val_accuracy: 0.4286\n",
      "Epoch 2/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0841 - accuracy: 0.3151 - val_loss: 1.7985 - val_accuracy: 0.4762\n",
      "Epoch 3/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.9309 - accuracy: 0.3699 - val_loss: 2.0176 - val_accuracy: 0.3333\n",
      "Epoch 4/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.0836 - accuracy: 0.2466 - val_loss: 1.8817 - val_accuracy: 0.3810\n",
      "Epoch 5/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.8177 - accuracy: 0.3562 - val_loss: 1.8421 - val_accuracy: 0.4762\n",
      "Epoch 6/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.6699 - accuracy: 0.3973 - val_loss: 1.8031 - val_accuracy: 0.5238\n",
      "Epoch 7/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.5765 - accuracy: 0.4521 - val_loss: 1.7718 - val_accuracy: 0.5238\n",
      "Epoch 8/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.5068 - accuracy: 0.4521 - val_loss: 1.7251 - val_accuracy: 0.5238\n",
      "Epoch 9/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.2961 - accuracy: 0.5068 - val_loss: 1.5741 - val_accuracy: 0.5238\n",
      "Epoch 10/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.4437 - accuracy: 0.4247 - val_loss: 1.3415 - val_accuracy: 0.5238\n",
      "Epoch 11/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.3226 - accuracy: 0.4932 - val_loss: 1.2138 - val_accuracy: 0.5238\n",
      "Epoch 12/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.3944 - accuracy: 0.4932 - val_loss: 1.1830 - val_accuracy: 0.5238\n",
      "Epoch 13/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.1361 - accuracy: 0.5205 - val_loss: 1.1656 - val_accuracy: 0.5238\n",
      "Epoch 14/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0667 - accuracy: 0.5753 - val_loss: 1.1410 - val_accuracy: 0.5238\n",
      "Epoch 15/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.2156 - accuracy: 0.5342 - val_loss: 1.1483 - val_accuracy: 0.5238\n",
      "Epoch 16/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.0887 - accuracy: 0.5890 - val_loss: 1.1398 - val_accuracy: 0.5238\n",
      "Epoch 17/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.1145 - accuracy: 0.5753 - val_loss: 1.0993 - val_accuracy: 0.5238\n",
      "Epoch 18/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9475 - accuracy: 0.6027 - val_loss: 1.0793 - val_accuracy: 0.5238\n",
      "Epoch 19/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0634 - accuracy: 0.5890 - val_loss: 1.0936 - val_accuracy: 0.5238\n",
      "Epoch 20/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.1076 - accuracy: 0.6027 - val_loss: 1.0796 - val_accuracy: 0.5238\n",
      "Epoch 21/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.0772 - accuracy: 0.5479 - val_loss: 1.0899 - val_accuracy: 0.5238\n",
      "Epoch 22/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.1032 - accuracy: 0.6164 - val_loss: 1.0861 - val_accuracy: 0.5238\n",
      "Epoch 23/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0072 - accuracy: 0.5890 - val_loss: 1.1274 - val_accuracy: 0.5714\n",
      "Epoch 24/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0019 - accuracy: 0.6301 - val_loss: 1.0545 - val_accuracy: 0.5238\n",
      "Epoch 25/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9932 - accuracy: 0.5753 - val_loss: 1.0666 - val_accuracy: 0.5714\n",
      "Epoch 26/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0306 - accuracy: 0.6301 - val_loss: 1.0484 - val_accuracy: 0.5714\n",
      "Epoch 27/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9621 - accuracy: 0.6301 - val_loss: 1.0470 - val_accuracy: 0.5714\n",
      "Epoch 28/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9800 - accuracy: 0.5890 - val_loss: 1.0448 - val_accuracy: 0.5714\n",
      "Epoch 29/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9121 - accuracy: 0.6301 - val_loss: 1.0456 - val_accuracy: 0.5714\n",
      "Epoch 30/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9419 - accuracy: 0.5890 - val_loss: 1.0364 - val_accuracy: 0.5714\n",
      "Epoch 31/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9121 - accuracy: 0.6575 - val_loss: 1.0346 - val_accuracy: 0.5714\n",
      "Epoch 32/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8825 - accuracy: 0.6575 - val_loss: 1.0269 - val_accuracy: 0.5714\n",
      "Epoch 33/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8514 - accuracy: 0.6301 - val_loss: 1.0227 - val_accuracy: 0.5714\n",
      "Epoch 34/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8007 - accuracy: 0.6849 - val_loss: 0.9981 - val_accuracy: 0.5714\n",
      "Epoch 35/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8193 - accuracy: 0.6849 - val_loss: 0.9705 - val_accuracy: 0.5714\n",
      "Epoch 36/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8994 - accuracy: 0.6575 - val_loss: 1.0058 - val_accuracy: 0.5714\n",
      "Epoch 37/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.8603 - accuracy: 0.6164 - val_loss: 0.9877 - val_accuracy: 0.6190\n",
      "Epoch 38/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8535 - accuracy: 0.6712 - val_loss: 1.0166 - val_accuracy: 0.6190\n",
      "Epoch 39/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9497 - accuracy: 0.6164 - val_loss: 1.0081 - val_accuracy: 0.6190\n",
      "Epoch 40/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.8439 - accuracy: 0.6301 - val_loss: 0.9950 - val_accuracy: 0.6667\n",
      "Epoch 41/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7565 - accuracy: 0.6712 - val_loss: 0.9384 - val_accuracy: 0.7619\n",
      "Epoch 42/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8373 - accuracy: 0.6575 - val_loss: 0.9459 - val_accuracy: 0.7619\n",
      "Epoch 43/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8395 - accuracy: 0.6712 - val_loss: 1.0112 - val_accuracy: 0.6190\n",
      "Epoch 44/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7729 - accuracy: 0.6575 - val_loss: 0.9676 - val_accuracy: 0.7143\n",
      "Epoch 45/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7538 - accuracy: 0.7397 - val_loss: 0.9494 - val_accuracy: 0.7619\n",
      "Epoch 46/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7284 - accuracy: 0.7671 - val_loss: 0.8276 - val_accuracy: 0.7619\n",
      "Epoch 47/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8944 - accuracy: 0.6301 - val_loss: 0.8932 - val_accuracy: 0.6667\n",
      "Epoch 48/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7803 - accuracy: 0.6849 - val_loss: 0.8576 - val_accuracy: 0.7143\n",
      "Epoch 49/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7897 - accuracy: 0.6986 - val_loss: 0.8705 - val_accuracy: 0.7619\n",
      "Epoch 50/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7128 - accuracy: 0.7534 - val_loss: 0.8617 - val_accuracy: 0.7619\n",
      "Epoch 51/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8020 - accuracy: 0.6849 - val_loss: 0.8497 - val_accuracy: 0.7619\n",
      "Epoch 52/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7556 - accuracy: 0.6849 - val_loss: 0.8024 - val_accuracy: 0.8095\n",
      "Epoch 53/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7270 - accuracy: 0.7260 - val_loss: 0.7552 - val_accuracy: 0.8095\n",
      "Epoch 54/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6723 - accuracy: 0.7671 - val_loss: 0.6949 - val_accuracy: 0.8095\n",
      "Epoch 55/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6643 - accuracy: 0.7671 - val_loss: 0.7836 - val_accuracy: 0.8095\n",
      "Epoch 56/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7493 - accuracy: 0.7808 - val_loss: 0.7932 - val_accuracy: 0.8095\n",
      "Epoch 57/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7279 - accuracy: 0.7671 - val_loss: 0.7679 - val_accuracy: 0.8095\n",
      "Epoch 58/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6335 - accuracy: 0.7808 - val_loss: 0.7430 - val_accuracy: 0.8095\n",
      "Epoch 59/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6581 - accuracy: 0.7534 - val_loss: 0.7686 - val_accuracy: 0.8095\n",
      "Epoch 60/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7182 - accuracy: 0.7260 - val_loss: 0.7650 - val_accuracy: 0.8571\n",
      "Epoch 61/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6588 - accuracy: 0.7808 - val_loss: 0.7346 - val_accuracy: 0.8571\n",
      "Epoch 62/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7496 - accuracy: 0.7808 - val_loss: 0.7633 - val_accuracy: 0.8571\n",
      "Epoch 63/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6523 - accuracy: 0.7397 - val_loss: 0.6711 - val_accuracy: 0.8571\n",
      "Epoch 64/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6035 - accuracy: 0.8082 - val_loss: 0.6692 - val_accuracy: 0.8571\n",
      "Epoch 65/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6335 - accuracy: 0.7671 - val_loss: 0.6798 - val_accuracy: 0.8571\n",
      "Epoch 66/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6017 - accuracy: 0.7808 - val_loss: 0.6742 - val_accuracy: 0.8571\n",
      "Epoch 67/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7332 - accuracy: 0.7397 - val_loss: 0.6614 - val_accuracy: 0.8571\n",
      "Epoch 68/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6287 - accuracy: 0.7671 - val_loss: 0.6685 - val_accuracy: 0.8571\n",
      "Epoch 69/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7147 - accuracy: 0.7671 - val_loss: 0.6650 - val_accuracy: 0.8571\n",
      "Epoch 70/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6579 - accuracy: 0.7808 - val_loss: 0.6775 - val_accuracy: 0.8571\n",
      "Epoch 71/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5674 - accuracy: 0.8082 - val_loss: 0.6317 - val_accuracy: 0.8571\n",
      "Epoch 72/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6251 - accuracy: 0.7808 - val_loss: 0.6219 - val_accuracy: 0.8571\n",
      "Epoch 73/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6074 - accuracy: 0.7808 - val_loss: 0.6395 - val_accuracy: 0.8095\n",
      "Epoch 74/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5863 - accuracy: 0.7671 - val_loss: 0.5939 - val_accuracy: 0.8571\n",
      "Epoch 75/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5099 - accuracy: 0.8630 - val_loss: 0.5700 - val_accuracy: 0.8571\n",
      "Epoch 76/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5584 - accuracy: 0.8219 - val_loss: 0.5943 - val_accuracy: 0.8571\n",
      "Epoch 77/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6239 - accuracy: 0.8082 - val_loss: 0.5909 - val_accuracy: 0.9048\n",
      "Epoch 78/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5860 - accuracy: 0.8082 - val_loss: 0.6145 - val_accuracy: 0.8571\n",
      "Epoch 79/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6913 - accuracy: 0.8356 - val_loss: 0.6035 - val_accuracy: 0.8571\n",
      "Epoch 80/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5331 - accuracy: 0.8219 - val_loss: 0.6014 - val_accuracy: 0.8571\n",
      "Epoch 81/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5485 - accuracy: 0.8356 - val_loss: 0.5787 - val_accuracy: 0.8571\n",
      "Epoch 82/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5644 - accuracy: 0.8082 - val_loss: 0.6151 - val_accuracy: 0.8571\n",
      "Epoch 83/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6255 - accuracy: 0.8082 - val_loss: 0.5311 - val_accuracy: 0.8571\n",
      "Epoch 84/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5774 - accuracy: 0.8082 - val_loss: 0.5675 - val_accuracy: 0.9048\n",
      "Epoch 85/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5058 - accuracy: 0.8082 - val_loss: 0.5288 - val_accuracy: 0.9048\n",
      "Epoch 86/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4874 - accuracy: 0.8493 - val_loss: 0.5073 - val_accuracy: 0.9048\n",
      "Epoch 87/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5427 - accuracy: 0.7534 - val_loss: 0.5121 - val_accuracy: 0.9048\n",
      "Epoch 88/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5871 - accuracy: 0.7808 - val_loss: 0.5201 - val_accuracy: 0.9048\n",
      "Epoch 89/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5958 - accuracy: 0.7945 - val_loss: 0.5608 - val_accuracy: 0.9048\n",
      "Epoch 90/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5724 - accuracy: 0.8082 - val_loss: 0.5432 - val_accuracy: 0.9048\n",
      "Epoch 91/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4718 - accuracy: 0.8630 - val_loss: 0.5410 - val_accuracy: 0.9048\n",
      "Epoch 92/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4851 - accuracy: 0.8630 - val_loss: 0.5373 - val_accuracy: 0.9048\n",
      "Epoch 93/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5375 - accuracy: 0.8219 - val_loss: 0.5239 - val_accuracy: 0.9048\n",
      "Epoch 94/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4796 - accuracy: 0.8356 - val_loss: 0.5044 - val_accuracy: 0.9048\n",
      "Epoch 95/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5643 - accuracy: 0.8219 - val_loss: 0.5300 - val_accuracy: 0.9048\n",
      "Epoch 96/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5355 - accuracy: 0.8082 - val_loss: 0.5122 - val_accuracy: 0.9048\n",
      "Epoch 97/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4409 - accuracy: 0.8630 - val_loss: 0.4752 - val_accuracy: 0.9524\n",
      "Epoch 98/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4433 - accuracy: 0.8219 - val_loss: 0.4969 - val_accuracy: 0.9048\n",
      "Epoch 99/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4596 - accuracy: 0.8493 - val_loss: 0.4790 - val_accuracy: 0.9048\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.8630 - val_loss: 0.4920 - val_accuracy: 0.9048\n",
      "Epoch 101/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4754 - accuracy: 0.8630 - val_loss: 0.4912 - val_accuracy: 0.9048\n",
      "Epoch 102/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4485 - accuracy: 0.8630 - val_loss: 0.4744 - val_accuracy: 0.9048\n",
      "Epoch 103/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3834 - accuracy: 0.8767 - val_loss: 0.4503 - val_accuracy: 0.9048\n",
      "Epoch 104/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4392 - accuracy: 0.9041 - val_loss: 0.4522 - val_accuracy: 0.9048\n",
      "Epoch 105/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4996 - accuracy: 0.7945 - val_loss: 0.5126 - val_accuracy: 0.9048\n",
      "Epoch 106/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4678 - accuracy: 0.8356 - val_loss: 0.4964 - val_accuracy: 0.9048\n",
      "Epoch 107/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4510 - accuracy: 0.8630 - val_loss: 0.4909 - val_accuracy: 0.9048\n",
      "Epoch 108/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4540 - accuracy: 0.8356 - val_loss: 0.4647 - val_accuracy: 0.9048\n",
      "Epoch 109/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4344 - accuracy: 0.8493 - val_loss: 0.4349 - val_accuracy: 0.9048\n",
      "Epoch 110/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3797 - accuracy: 0.8493 - val_loss: 0.4651 - val_accuracy: 0.9048\n",
      "Epoch 111/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3792 - accuracy: 0.9041 - val_loss: 0.4314 - val_accuracy: 0.9048\n",
      "Epoch 112/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5177 - accuracy: 0.8219 - val_loss: 0.6546 - val_accuracy: 0.8571\n",
      "Epoch 113/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4859 - accuracy: 0.8219 - val_loss: 0.4836 - val_accuracy: 0.9524\n",
      "Epoch 114/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3436 - accuracy: 0.8767 - val_loss: 0.4675 - val_accuracy: 0.9048\n",
      "Epoch 115/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4888 - accuracy: 0.8493 - val_loss: 0.4491 - val_accuracy: 0.9048\n",
      "Epoch 116/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3587 - accuracy: 0.8630 - val_loss: 0.4859 - val_accuracy: 0.9048\n",
      "Epoch 117/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3698 - accuracy: 0.8904 - val_loss: 0.4562 - val_accuracy: 0.9048\n",
      "Epoch 118/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3168 - accuracy: 0.9452 - val_loss: 0.4429 - val_accuracy: 0.9524\n",
      "Epoch 119/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.8493 - val_loss: 0.5113 - val_accuracy: 0.9048\n",
      "Epoch 120/150\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3691 - accuracy: 0.8904 - val_loss: 0.4818 - val_accuracy: 0.9048\n",
      "Epoch 121/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.8630 - val_loss: 0.4496 - val_accuracy: 0.9524\n",
      "Epoch 122/150\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4651 - accuracy: 0.8356 - val_loss: 0.4462 - val_accuracy: 0.9524\n",
      "Epoch 123/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3550 - accuracy: 0.8904 - val_loss: 0.4308 - val_accuracy: 0.9524\n",
      "Epoch 124/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3477 - accuracy: 0.8767 - val_loss: 0.4543 - val_accuracy: 0.9524\n",
      "Epoch 125/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3751 - accuracy: 0.8767 - val_loss: 0.4305 - val_accuracy: 0.9048\n",
      "Epoch 126/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2855 - accuracy: 0.9178 - val_loss: 0.4141 - val_accuracy: 0.9524\n",
      "Epoch 127/150\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4780 - accuracy: 0.8219 - val_loss: 0.4563 - val_accuracy: 0.8571\n",
      "Epoch 128/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3043 - accuracy: 0.9452 - val_loss: 0.4172 - val_accuracy: 0.9524\n",
      "Epoch 129/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3345 - accuracy: 0.8767 - val_loss: 0.4076 - val_accuracy: 0.9524\n",
      "Epoch 130/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3093 - accuracy: 0.9178 - val_loss: 0.4254 - val_accuracy: 0.9524\n",
      "Epoch 131/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3193 - accuracy: 0.8767 - val_loss: 0.5060 - val_accuracy: 0.9048\n",
      "Epoch 132/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3195 - accuracy: 0.9041 - val_loss: 0.4386 - val_accuracy: 0.9048\n",
      "Epoch 133/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2934 - accuracy: 0.9452 - val_loss: 0.4439 - val_accuracy: 0.9048\n",
      "Epoch 134/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3089 - accuracy: 0.8904 - val_loss: 0.3876 - val_accuracy: 0.9048\n",
      "Epoch 135/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2806 - accuracy: 0.9315 - val_loss: 0.4159 - val_accuracy: 0.9048\n",
      "Epoch 136/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3348 - accuracy: 0.8767 - val_loss: 0.4197 - val_accuracy: 0.9048\n",
      "Epoch 137/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3521 - accuracy: 0.8356 - val_loss: 0.4139 - val_accuracy: 0.9048\n",
      "Epoch 138/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3092 - accuracy: 0.9041 - val_loss: 0.4066 - val_accuracy: 0.9048\n",
      "Epoch 139/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3387 - accuracy: 0.8767 - val_loss: 0.4137 - val_accuracy: 0.9048\n",
      "Epoch 140/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2367 - accuracy: 0.9315 - val_loss: 0.3866 - val_accuracy: 0.9048\n",
      "Epoch 141/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2342 - accuracy: 0.9452 - val_loss: 0.3767 - val_accuracy: 0.9524\n",
      "Epoch 142/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2440 - accuracy: 0.9315 - val_loss: 0.3505 - val_accuracy: 0.9524\n",
      "Epoch 143/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2633 - accuracy: 0.9315 - val_loss: 0.3755 - val_accuracy: 0.9048\n",
      "Epoch 144/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2260 - accuracy: 0.9589 - val_loss: 0.3713 - val_accuracy: 0.9048\n",
      "Epoch 145/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2899 - accuracy: 0.9178 - val_loss: 0.3545 - val_accuracy: 0.9524\n",
      "Epoch 146/150\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2605 - accuracy: 0.9178 - val_loss: 0.3604 - val_accuracy: 0.9048\n",
      "Epoch 147/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3005 - accuracy: 0.8767 - val_loss: 0.3752 - val_accuracy: 0.9048\n",
      "Epoch 148/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2990 - accuracy: 0.9178 - val_loss: 0.4191 - val_accuracy: 0.8571\n",
      "Epoch 149/150\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2129 - accuracy: 0.9452 - val_loss: 0.3663 - val_accuracy: 0.9048\n",
      "Epoch 150/150\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2827 - accuracy: 0.9315 - val_loss: 0.3659 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x227b8fecb50>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "model = CNN(X_train.shape[1:])\n",
    "model.compile(optimizers.RMSprop(lr=0.0005, decay=1e-6), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=150, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8160a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape):\n",
    "    from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "    from keras.models import Sequential, Model\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    from keras import regularizers, optimizers\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 4)))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Conv2D(4, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e01c5afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if save_path:\n",
    "#     with open(save_path + \"/model.json\", \"w\") as json_file:\n",
    "#         json_file.write(model.to_json())\n",
    "#     model.save_weights(save_path + \"/model.h5\")\n",
    "\n",
    "    # json_file = open('model.json', 'r')\n",
    "    # loaded_model_json = json_file.read()\n",
    "\n",
    "# Test model quality\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "print(classification_report(np.argmax(model.predict(X_test), axis=-1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a776854d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 0, 0, 9], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "26f839f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 0, 0, 0, 9], dtype=int64),\n",
       " array([2, 3, 0, 0, 0, 9], dtype=int64))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test), axis=-1), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448b75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
